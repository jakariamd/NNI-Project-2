{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559a9102",
   "metadata": {},
   "source": [
    "# Load Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "from nni.compression.pytorch.utils import count_flops_params\n",
    "import time\n",
    "\n",
    "from mnist_model import Net, train, test, device, optimizer_scheduler_generator, trainer, calibration\n",
    "\n",
    "# Load pretrained model\n",
    "model = torch.load(\"mnist_cnn.pt\")\n",
    "model.eval()\n",
    "\n",
    "# show the model stbructure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4435816",
   "metadata": {},
   "source": [
    "### Performance and statistics of pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65e18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "Pretrained model Accuracy:  99.19%, Test-time:  1.6402s\n"
     ]
    }
   ],
   "source": [
    "## Performance \n",
    "start = time.time()\n",
    "pre_best_acc = test(model, device)\n",
    "pre_test_time = time.time() - start\n",
    "\n",
    "print(f'Pretrained model Accuracy: {pre_best_acc: .2f}%, Test-time: {pre_test_time: .4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba20bd",
   "metadata": {},
   "source": [
    "# Quantizing Model  with QAT Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fb9e4",
   "metadata": {},
   "source": [
    "## Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining  configuration List\n",
    "config_list = [{\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_types': ['Conv2d']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db96c39",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Construct the ObserverQuantizer. Note that currently ObserverQuantizer only works in evaluation mode.\n",
    "    \n",
    "from nni.algorithms.compression.pytorch.quantization import ObserverQuantizer\n",
    "\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "quantizer = ObserverQuantizer(model, config_list, optimizer)\n",
    "# Use the test data set to do calibration, this will not change the model parameters\n",
    "calibration(model)\n",
    "# obtain the quantization information and switch the model to \"accuracy verification\" mode\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03805b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0307, Accuracy: 9910/10000 (99.10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finetune the model \n",
    "total_epoch = 3  \n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-11 17:12:41] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-11 17:12:41] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'tracked_max_weight': 0.518154501914978, 'tracked_min_weight': -0.518154501914978, 'tracked_qmin_weight': -127, 'tracked_qmax_weight': 127, 'input_bits': 8, 'tracked_min_input': -0.40611180663108826, 'tracked_max_input': 2.8174006938934326, 'tracked_qmin_input': 0, 'tracked_qmax_input': 127}, 'conv2': {'weight_bits': 8, 'tracked_max_weight': 0.32586750388145447, 'tracked_min_weight': -0.32586750388145447, 'tracked_qmin_weight': -127, 'tracked_qmax_weight': 127, 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 3.26343035697937, 'tracked_qmin_input': 0, 'tracked_qmax_input': 127}}\n"
     ]
    }
   ],
   "source": [
    "## export model and get calibration_config\n",
    "\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef3636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0299, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Pretrained model Accuracy:  99.08%, Test-time:  1.4823s, Speed-up:  1.11x\n"
     ]
    }
   ],
   "source": [
    "## Performance \n",
    "start = time.time()\n",
    "best_acc = test(model, device)\n",
    "test_time = time.time() - start\n",
    "\n",
    "print(f'Pretrained model Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61af61a",
   "metadata": {},
   "source": [
    "## Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5209f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = torch.load(\"mnist_cnn.pt\")\n",
    "model.eval()\n",
    "\n",
    "config_list = [{\n",
    "    'quant_types': ['weight', 'input'],\n",
    "    'quant_bits': {'weight': 8, 'input': 8},\n",
    "    'op_names': ['conv1', 'conv2']\n",
    "}, {\n",
    "    'quant_types': ['output', 'weight', 'input'],\n",
    "    'quant_bits': {'output': 8, 'weight': 8, 'input': 8},\n",
    "    'op_names': ['fc1', 'fc2'],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ece5920",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Construct the ObserverQuantizer. Note that currently ObserverQuantizer only works in evaluation mode.\n",
    "    \n",
    "from nni.algorithms.compression.pytorch.quantization import ObserverQuantizer\n",
    "\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "quantizer = ObserverQuantizer(model, config_list, optimizer)\n",
    "# Use the test data set to do calibration, this will not change the model parameters\n",
    "calibration(model)\n",
    "# obtain the quantization information and switch the model to \"accuracy verification\" mode\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d60ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 9918/10000 (99.18%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finetune the model \n",
    "total_epoch = 3  \n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0a9abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-11 17:14:28] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-11 17:14:28] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'tracked_max_weight': 0.518154501914978, 'tracked_min_weight': -0.518154501914978, 'tracked_qmin_weight': -127, 'tracked_qmax_weight': 127, 'input_bits': 8, 'tracked_min_input': -0.40611180663108826, 'tracked_max_input': 2.8174006938934326, 'tracked_qmin_input': 0, 'tracked_qmax_input': 127}, 'conv2': {'weight_bits': 8, 'tracked_max_weight': 0.32586750388145447, 'tracked_min_weight': -0.32586750388145447, 'tracked_qmin_weight': -127, 'tracked_qmax_weight': 127, 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 3.2396812438964844, 'tracked_qmin_input': 0, 'tracked_qmax_input': 127}, 'fc1': {'weight_bits': 8, 'tracked_max_weight': 0.17832523584365845, 'tracked_min_weight': -0.17832523584365845, 'tracked_qmin_weight': -127, 'tracked_qmax_weight': 127, 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 3.4713125228881836, 'tracked_qmin_input': 0, 'tracked_qmax_input': 127, 'output_bits': 8, 'tracked_min_output': -10.486841201782227, 'tracked_max_output': 10.994269371032715, 'tracked_qmin_output': 0, 'tracked_qmax_output': 127}, 'fc2': {'weight_bits': 8, 'tracked_max_weight': 0.43777063488960266, 'tracked_min_weight': -0.43777063488960266, 'tracked_qmin_weight': -127, 'tracked_qmax_weight': 127, 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 10.828486442565918, 'tracked_qmin_input': 0, 'tracked_qmax_input': 127, 'output_bits': 8, 'tracked_min_output': -41.597259521484375, 'tracked_max_output': 12.865132331848145, 'tracked_qmin_output': 0, 'tracked_qmax_output': 127}}\n"
     ]
    }
   ],
   "source": [
    "## export model and get calibration_config\n",
    "\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecee868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "Pretrained model Accuracy:  99.19%, Test-time:  1.5184s, Speed-up:  1.08x\n"
     ]
    }
   ],
   "source": [
    "## Performance \n",
    "start = time.time()\n",
    "best_acc = test(model, device)\n",
    "test_time = time.time() - start\n",
    "\n",
    "print(f'Pretrained model Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
