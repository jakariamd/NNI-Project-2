{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559a9102",
   "metadata": {},
   "source": [
    "# Load Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "from nni.compression.pytorch.utils import count_flops_params\n",
    "import time\n",
    "\n",
    "from mnist_model import Net, train, test, device, optimizer_scheduler_generator, trainer, test_trt\n",
    "\n",
    "# Load pretrained model\n",
    "model = torch.load(\"mnist_cnn.pt\")\n",
    "model.eval()\n",
    "\n",
    "# show the model stbructure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4435816",
   "metadata": {},
   "source": [
    "### Performance and statistics of pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65e18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "Pretrained model Accuracy:  99.19%, Test-time:  1.5021s\n"
     ]
    }
   ],
   "source": [
    "## Performance \n",
    "start = time.time()\n",
    "pre_best_acc = test(model, device)\n",
    "pre_test_time = time.time() - start\n",
    "\n",
    "print(f'Pretrained model Accuracy: {pre_best_acc: .2f}%, Test-time: {pre_test_time: .4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba20bd",
   "metadata": {},
   "source": [
    "# Quantizing Model  with QAT Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fb9e4",
   "metadata": {},
   "source": [
    "## Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining  configuration List\n",
    "config_list = [{\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_types': ['Conv2d']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7431a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Quantization \n",
    "from nni.algorithms.compression.pytorch.quantization import QAT_Quantizer\n",
    "dummy_input = torch.rand(3, 1, 28, 28).to(device)\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "quantizer = QAT_Quantizer(model, config_list, optimizer, dummy_input)\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03805b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0387, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 9908/10000 (99.08%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finetune the model \n",
    "total_epoch = 3  \n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-11 16:47:41] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-11 16:47:41] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'weight_scale': tensor([0.0036], device='cuda:0'), 'weight_zero_point': tensor([135.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': -0.4242129623889923, 'tracked_max_input': 2.821486711502075}, 'conv2': {'weight_bits': 8, 'weight_scale': tensor([0.0029], device='cuda:0'), 'weight_zero_point': tensor([130.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 2.627883195877075}}\n"
     ]
    }
   ],
   "source": [
    "## export model and get calibration_config\n",
    "\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef3636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Pretrained model Accuracy:  99.08%, Test-time:  1.5405s, Speed-up:  0.98x\n"
     ]
    }
   ],
   "source": [
    "## Performance \n",
    "start = time.time()\n",
    "best_acc = test(model, device)\n",
    "test_time = time.time() - start\n",
    "\n",
    "print(f'Pretrained model Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61af61a",
   "metadata": {},
   "source": [
    "## Configuration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5209f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = torch.load(\"mnist_cnn.pt\")\n",
    "model.eval()\n",
    "\n",
    "configure_list = [{\n",
    "    'quant_types': ['weight', 'input'],\n",
    "    'quant_bits': {'weight': 8, 'input': 8},\n",
    "    'op_names': ['conv1', 'conv2']\n",
    "}, {\n",
    "    'quant_types': ['output', 'weight', 'input'],\n",
    "    'quant_bits': {'output': 8, 'weight': 8, 'input': 8},\n",
    "    'op_names': ['fc1', 'fc2'],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ece5920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): QuantizerModuleWrapper(\n",
       "    (module): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc2): QuantizerModuleWrapper(\n",
       "    (module): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Quantization \n",
    "from nni.algorithms.compression.pytorch.quantization import QAT_Quantizer\n",
    "dummy_input = torch.rand(3, 1, 28, 28).to(device)\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "quantizer = QAT_Quantizer(model, configure_list, optimizer, dummy_input)\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88d60ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0425, Accuracy: 9872/10000 (98.72%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0343, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9919/10000 (99.19%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finetune the model \n",
    "total_epoch = 3  \n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c0a9abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-11 16:58:34] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-11 16:58:34] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'weight_scale': tensor([0.0038], device='cuda:0'), 'weight_zero_point': tensor([138.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': -0.4242129623889923, 'tracked_max_input': 2.821486711502075}, 'conv2': {'weight_bits': 8, 'weight_scale': tensor([0.0028], device='cuda:0'), 'weight_zero_point': tensor([140.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 2.588933229446411}, 'fc1': {'weight_bits': 8, 'weight_scale': tensor([0.0014], device='cuda:0'), 'weight_zero_point': tensor([122.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 4.223904609680176, 'output_bits': 8, 'tracked_min_output': -9.732779502868652, 'tracked_max_output': 8.64108657836914}, 'fc2': {'weight_bits': 8, 'weight_scale': tensor([0.0033], device='cuda:0'), 'weight_zero_point': tensor([161.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 17.293052673339844, 'output_bits': 8, 'tracked_min_output': -47.388824462890625, 'tracked_max_output': 18.005813598632812}}\n"
     ]
    }
   ],
   "source": [
    "## export model and get calibration_config\n",
    "\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ecee868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 9921/10000 (99.21%)\n",
      "\n",
      "Pretrained model Accuracy:  99.21%, Test-time:  1.5821s, Speed-up:  0.95x\n"
     ]
    }
   ],
   "source": [
    "## Performance \n",
    "start = time.time()\n",
    "best_acc = test(model, device)\n",
    "test_time = time.time() - start\n",
    "\n",
    "print(f'Pretrained model Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
