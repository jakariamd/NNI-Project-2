{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559a9102",
   "metadata": {},
   "source": [
    "# Load Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63519f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "from nni.compression.pytorch.utils import count_flops_params\n",
    "import time\n",
    "\n",
    "from mnist_model import Net, train, test, device, optimizer_scheduler_generator, trainer, test_trt\n",
    "\n",
    "# Load pretrained model\n",
    "model = torch.load(\"mnist_cnn.pt\")\n",
    "model.eval()\n",
    "\n",
    "# show the model stbructure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4435816",
   "metadata": {},
   "source": [
    "### Performance and statistics of pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65e18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "| Index | Name  |  Type  |  Weight Shape  |    Input Size   |   Output Size   |  FLOPs   | #Params |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "|   0   | conv1 | Conv2d | (32, 1, 3, 3)  |  (3, 1, 28, 28) | (3, 32, 26, 26) |  194688  |   320   |\n",
      "|   1   | conv2 | Conv2d | (64, 32, 3, 3) | (3, 32, 26, 26) | (3, 64, 24, 24) | 10616832 |  18496  |\n",
      "|   2   | fc1   | Linear |  (128, 9216)   |    (3, 9216)    |     (3, 128)    | 1179648  | 1179776 |\n",
      "|   3   | fc2   | Linear |   (10, 128)    |     (3, 128)    |     (3, 10)     |   1280   |   1290  |\n",
      "+-------+-------+--------+----------------+-----------------+-----------------+----------+---------+\n",
      "FLOPs total: 11992448\n",
      "#Params total: 1199882\n",
      "Pretrained model FLOPs 11.99 M, #Params: 1.20M, Accuracy:  99.19%, Test-time:  1.5112s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pre_best_acc = test(model, device)\n",
    "pre_test_time = time.time() - start\n",
    "\n",
    "pre_flops, pre_params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%, Test-time: {pre_test_time: .4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba20bd",
   "metadata": {},
   "source": [
    "# Quantizing Model  with QAT Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fb9e4",
   "metadata": {},
   "source": [
    "## Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining  configuration List\n",
    "config_list = [{\n",
    "    'quant_types': ['input', 'weight'],\n",
    "    'quant_bits': {'input': 8, 'weight': 8},\n",
    "    'op_types': ['Conv2d']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7431a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): QuantizerModuleWrapper(\n",
       "    (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nni.algorithms.compression.pytorch.quantization import QAT_Quantizer\n",
    "dummy_input = torch.rand(3, 1, 28, 28).to(device)\n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "quantizer = QAT_Quantizer(model, config_list, optimizer, dummy_input)\n",
    "quantizer.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03805b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 9906/10000 (99.06%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Finetune the model \n",
    "total_epoch = 3  \n",
    "optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425133b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-11 14:57:02] \u001b[32mModel state_dict saved to ./log/mnist_model.pth\u001b[0m\n",
      "[2022-10-11 14:57:02] \u001b[32mMask dict saved to ./log/mnist_calibration.pth\u001b[0m\n",
      "calibration_config:  {'conv1': {'weight_bits': 8, 'weight_scale': tensor([0.0037], device='cuda:0'), 'weight_zero_point': tensor([142.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': -0.4242129623889923, 'tracked_max_input': 2.821486711502075}, 'conv2': {'weight_bits': 8, 'weight_scale': tensor([0.0030], device='cuda:0'), 'weight_zero_point': tensor([138.], device='cuda:0'), 'input_bits': 8, 'tracked_min_input': 0.0, 'tracked_max_input': 2.997408151626587}}\n"
     ]
    }
   ],
   "source": [
    "## export model and get calibration_config\n",
    "\n",
    "model_path = \"./log/mnist_model.pth\"\n",
    "calibration_path = \"./log/mnist_calibration.pth\"\n",
    "calibration_config = quantizer.export_model(model_path, calibration_path)\n",
    "\n",
    "print(\"calibration_config: \", calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3636c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0b90df",
   "metadata": {},
   "source": [
    "## build tensorRT engine to make a real speedup\n",
    "from nni.compression.pytorch.quantization_speedup import ModelSpeedupTensorRT\n",
    "input_shape = (1, 1, 28, 28)\n",
    "engine = ModelSpeedupTensorRT(model, input_shape, config=calibration_config, batchsize=64)\n",
    "engine.compress()\n",
    "test_trt(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ab23e",
   "metadata": {},
   "source": [
    "from nni.compression.pytorch.pruning import ADMMPruner\n",
    "from nni.compression.pytorch.pruning import ActivationMeanRankPruner\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "import nni\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pruner_function(config_list):\n",
    "\n",
    "    model = torch.load(\"mnist_cnn.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    traced_optimizer = nni.trace(optim.Adadelta)(model.parameters(), lr=1.0)\n",
    "    criterion = F.nll_loss\n",
    "    \n",
    "    # Using ADMMPruner to prune the model and generate the masks.\n",
    "    pruner = ADMMPruner(model, config_list, trainer, traced_optimizer, criterion, iterations=5, training_epochs=1, granularity='coarse-grained')\n",
    "    \n",
    "    # pruner = ActivationMeanRankPruner(model, config_list, trainer, traced_optimizer, criterion, training_batches=20)\n",
    "    \n",
    "    # show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "    #print(model)\n",
    "\n",
    "    # compress the model and generate the masks\n",
    "    _, masks = pruner.compress()\n",
    "\n",
    "    # show the masks sparsity\n",
    "    print(\"Showing the masks sparsity\")\n",
    "    for name, mask in masks.items():\n",
    "        print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))\n",
    "\n",
    "\n",
    "    # need to unwrap the model, if the model is wrapped before speedup\n",
    "    pruner._unwrap_model()\n",
    "\n",
    "    # speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "    ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
    "\n",
    "    #print(\"Model after speedup\")\n",
    "    #print(model)\n",
    "\n",
    "    optimizer, scheduler = optimizer_scheduler_generator(model)\n",
    "    \n",
    "    # fine- tuning model compacted model\n",
    "    # tuning and evaluate the model on MNIST dataset\n",
    "    total_epoch = 3\n",
    "    \n",
    "    for epoch in range(1, total_epoch + 1):\n",
    "        train(model, device, optimizer=optimizer, epoch=epoch)\n",
    "        test(model, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f903070",
   "metadata": {},
   "source": [
    "def Perfomance_function(model):\n",
    "    print(\"Model after speedup\")\n",
    "    print(model)\n",
    "    \n",
    "    start = time.time()\n",
    "    best_acc = test(model, device)\n",
    "    test_time = time.time() - start\n",
    "\n",
    "    flops, params, _ = count_flops_params(model, torch.randn([3, 1, 28, 28]).to(device))\n",
    "\n",
    "    print(f'Pretrained model FLOPs {pre_flops/1e6:.2f} M, #Params: {pre_params/1e6:.2f}M, Accuracy: {pre_best_acc: .2f}%, , Test-time: {pre_test_time: .4f}s')\n",
    "    print(f'Finetuned model FLOPs {flops/1e6:.2f} M, #Params: {params/1e6:.2f}M, Accuracy: {best_acc: .2f}%, Test-time: {test_time: .4f}s, Speed-up: {pre_test_time/test_time: .2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029e382",
   "metadata": {},
   "source": [
    "## ADMM Configuration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555e5aa",
   "metadata": {},
   "source": [
    "config_list = [{\n",
    "    'sparsity_per_layer': 0.50,\n",
    "    'op_types': ['Linear', 'Conv2d']\n",
    "}, {\n",
    "    'exclude': True,\n",
    "    'op_names': ['fc2']\n",
    "}]\n",
    "\n",
    "\n",
    "pruned_model = pruner_function(config_list=config_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b55cad",
   "metadata": {},
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae4033",
   "metadata": {},
   "source": [
    "## ADMM Configuration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16c399",
   "metadata": {},
   "source": [
    "config_list = [{\n",
    "    'op_types': ['Conv2d'],\n",
    "    'total_sparsity': 0.5\n",
    "    }, {\n",
    "    'op_names': ['Linear'],\n",
    "    'total_sparsity': 0.8\n",
    "    },\n",
    "    {\n",
    "    'exclude': True,\n",
    "    'op_names': ['fc2']\n",
    "}]\n",
    "\n",
    "\n",
    "pruned_model = pruner_function(config_list=config_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc19d54",
   "metadata": {},
   "source": [
    "Perfomance_function(pruned_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
